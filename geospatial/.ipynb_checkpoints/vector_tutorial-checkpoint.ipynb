{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install geospatial vector packages\n",
    "!pip install geopandas fiona shapely matplotlib contextily rasterio scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Geospatial Tutorial - From Arrays to Shapefiles\n",
    "\n",
    "**The Vector Geospatial Stack:**\n",
    "- **Fiona**: Low-level vector I/O (read/write shapefiles, GeoJSON, etc.)\n",
    "- **Shapely**: Geometric operations (polygons, intersections, buffers)\n",
    "- **GeoPandas**: High-level spatial data analysis (\"pandas for GIS\")\n",
    "\n",
    "Perfect for: converting raster patterns to vectors, spatial analysis, GIS workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shapely\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import fiona\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "from shapely.ops import unary_union\n",
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "from rasterio.transform import from_bounds\n",
    "from skimage import measure\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import contextily as ctx\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"GeoPandas version: {gpd.__version__}\")\n",
    "print(f\"Fiona version: {fiona.__version__}\")\n",
    "print(f\"Shapely version: {shapely.__version__}\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = Path('vector_outputs')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "print(f\"Output directory: {output_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎨 Creating 2D Pattern Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interesting 2D pattern for polygon extraction\n",
    "def create_pattern_array(width=800, height=600, bounds=(-10, 40, -5, 45)):\n",
    "    \"\"\"Create 2D array with interesting patterns for polygon extraction\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Create coordinate arrays\n",
    "    x = np.linspace(bounds[0], bounds[2], width)\n",
    "    y = np.linspace(bounds[1], bounds[3], height)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # Base pattern with multiple scales\n",
    "    pattern = np.zeros_like(X)\n",
    "    \n",
    "    # Large circular features (\"islands\")\n",
    "    center1 = (-8.5, 42.5)\n",
    "    center2 = (-6.5, 43.8)\n",
    "    center3 = (-7.2, 41.2)\n",
    "    \n",
    "    island1 = np.exp(-((X - center1[0])**2 + (Y - center1[1])**2) / 0.3)\n",
    "    island2 = np.exp(-((X - center2[0])**2 + (Y - center2[1])**2) / 0.2)\n",
    "    island3 = np.exp(-((X - center3[0])**2 + (Y - center3[1])**2) / 0.4)\n",
    "    \n",
    "    pattern += island1 + island2 + island3\n",
    "    \n",
    "    # Linear features (\"rivers\" or \"ridges\")\n",
    "    ridge1 = 0.8 * np.exp(-((X + 8)**2 + (Y - 2*X - 90)**2) / 0.05)\n",
    "    ridge2 = 0.6 * np.exp(-((Y - 43)**2 + (X + 7.5)**2) / 0.02)\n",
    "    \n",
    "    pattern += ridge1 + ridge2\n",
    "    \n",
    "    # Complex wave pattern\n",
    "    waves = 0.4 * np.sin(X * 3) * np.cos(Y * 2) + 0.3 * np.sin(X * 8) * np.sin(Y * 5)\n",
    "    waves = np.maximum(waves, 0)  # Only positive parts\n",
    "    pattern += waves\n",
    "    \n",
    "    # Random speckle pattern\n",
    "    speckle = 0.5 * np.random.exponential(0.3, (height, width))\n",
    "    pattern += speckle\n",
    "    \n",
    "    # Smooth boundaries\n",
    "    from scipy import ndimage\n",
    "    pattern = ndimage.gaussian_filter(pattern, sigma=2)\n",
    "    \n",
    "    # Normalize to 0-1 range\n",
    "    pattern = (pattern - pattern.min()) / (pattern.max() - pattern.min())\n",
    "    \n",
    "    return pattern, bounds\n",
    "\n",
    "# Generate pattern\n",
    "pattern_data, bounds = create_pattern_array(800, 600, bounds=(-10, 40, -5, 45))\n",
    "print(f\"Pattern array created: {pattern_data.shape}\")\n",
    "print(f\"Value range: {pattern_data.min():.3f} to {pattern_data.max():.3f}\")\n",
    "print(f\"Geographic bounds: {bounds} (lon_min, lat_min, lon_max, lat_max)\")\n",
    "\n",
    "# Create geospatial transform\n",
    "transform = from_bounds(*bounds, pattern_data.shape[1], pattern_data.shape[0])\n",
    "print(f\"Pixel size: {abs(transform.a):.6f}° × {abs(transform.e):.6f}°\")\n",
    "\n",
    "# Visualize the pattern\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Full pattern\n",
    "im1 = axes[0].imshow(pattern_data, cmap='viridis', extent=bounds, aspect='equal')\n",
    "axes[0].set_title('2D Pattern Array (Full Range)')\n",
    "axes[0].set_xlabel('Longitude (°)')\n",
    "axes[0].set_ylabel('Latitude (°)')\n",
    "plt.colorbar(im1, ax=axes[0], label='Pattern Value')\n",
    "\n",
    "# Threshold visualization (>0.7)\n",
    "threshold = 0.7\n",
    "binary_pattern = pattern_data > threshold\n",
    "im2 = axes[1].imshow(binary_pattern, cmap='RdYlBu_r', extent=bounds, aspect='equal')\n",
    "axes[1].set_title(f'Thresholded Pattern (Values > {threshold})')\n",
    "axes[1].set_xlabel('Longitude (°)')\n",
    "axes[1].set_ylabel('Latitude (°)')\n",
    "plt.colorbar(im2, ax=axes[1], label='Above Threshold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "high_value_pixels = np.sum(binary_pattern)\n",
    "total_pixels = pattern_data.size\n",
    "print(f\"\\nPixels above threshold ({threshold}): {high_value_pixels:,} ({high_value_pixels/total_pixels*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Converting Array to Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert thresholded array to polygons using rasterio.features\n",
    "print(\"Converting raster pattern to vector polygons...\")\n",
    "\n",
    "def array_to_polygons(array, transform, threshold=0.7, min_area=0.01):\n",
    "    \"\"\"Convert 2D array to polygons using rasterio.features.shapes\"\"\"\n",
    "    \n",
    "    # Create binary mask\n",
    "    binary_mask = (array > threshold).astype(np.uint8)\n",
    "    \n",
    "    # Extract shapes (polygons) from binary mask\n",
    "    polygon_generator = shapes(binary_mask, transform=transform)\n",
    "    \n",
    "    polygons = []\n",
    "    areas = []\n",
    "    \n",
    "    for geom, value in polygon_generator:\n",
    "        if value == 1:  # Only high-value areas\n",
    "            poly = Polygon(geom['coordinates'][0])\n",
    "            area = poly.area\n",
    "            \n",
    "            # Filter by minimum area to remove noise\n",
    "            if area > min_area:\n",
    "                polygons.append(poly)\n",
    "                areas.append(area)\n",
    "    \n",
    "    return polygons, areas\n",
    "\n",
    "# Convert to polygons\n",
    "polygons, areas = array_to_polygons(pattern_data, transform, threshold=0.7, min_area=0.005)\n",
    "\n",
    "print(f\"Extracted {len(polygons)} polygons from pattern\")\n",
    "print(f\"Area statistics:\")\n",
    "print(f\"  Total area: {sum(areas):.3f} square degrees\")\n",
    "print(f\"  Largest polygon: {max(areas):.3f} square degrees\")\n",
    "print(f\"  Smallest polygon: {min(areas):.3f} square degrees\")\n",
    "print(f\"  Mean area: {np.mean(areas):.3f} square degrees\")\n",
    "\n",
    "# Alternative method using scikit-image contours\n",
    "def array_to_polygons_contour(array, transform, threshold=0.7, min_area=0.01):\n",
    "    \"\"\"Convert array to polygons using contour detection\"\"\"\n",
    "    \n",
    "    # Find contours\n",
    "    contours = measure.find_contours(array, threshold)\n",
    "    \n",
    "    polygons_contour = []\n",
    "    \n",
    "    for contour in contours:\n",
    "        # Convert pixel coordinates to geographic coordinates\n",
    "        geo_coords = []\n",
    "        for point in contour:\n",
    "            # Transform from array indices to geographic coordinates\n",
    "            lon, lat = rasterio.transform.xy(transform, point[0], point[1])\n",
    "            geo_coords.append((lon, lat))\n",
    "        \n",
    "        # Create polygon if we have enough points\n",
    "        if len(geo_coords) >= 3:\n",
    "            try:\n",
    "                poly = Polygon(geo_coords)\n",
    "                if poly.is_valid and poly.area > min_area:\n",
    "                    polygons_contour.append(poly)\n",
    "            except:\n",
    "                continue  # Skip invalid polygons\n",
    "    \n",
    "    return polygons_contour\n",
    "\n",
    "# Compare methods\n",
    "polygons_contour = array_to_polygons_contour(pattern_data, transform, threshold=0.7)\n",
    "print(f\"\\nComparison of extraction methods:\")\n",
    "print(f\"  Rasterio.features method: {len(polygons)} polygons\")\n",
    "print(f\"  Scikit-image contours:    {len(polygons_contour)} polygons\")\n",
    "\n",
    "# Use the rasterio method (typically more accurate for raster data)\n",
    "selected_polygons = polygons\n",
    "print(f\"\\nUsing rasterio.features method with {len(selected_polygons)} polygons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📄 Creating Shapefile with Fiona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create shapefile using Fiona (low-level approach)\n",
    "print(\"Creating shapefile with Fiona...\")\n",
    "\n",
    "def create_shapefile_fiona(polygons, output_path, crs='EPSG:4326'):\n",
    "    \"\"\"Create shapefile using Fiona\"\"\"\n",
    "    \n",
    "    # Define schema\n",
    "    schema = {\n",
    "        'geometry': 'Polygon',\n",
    "        'properties': {\n",
    "            'id': 'int',\n",
    "            'area': 'float',\n",
    "            'perimeter': 'float',\n",
    "            'compactness': 'float',\n",
    "            'category': 'str'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create shapefile\n",
    "    with fiona.open(output_path, 'w', driver='ESRI Shapefile', \n",
    "                   schema=schema, crs=crs) as shp:\n",
    "        \n",
    "        for i, poly in enumerate(polygons):\n",
    "            # Calculate properties\n",
    "            area = poly.area\n",
    "            perimeter = poly.length\n",
    "            compactness = 4 * np.pi * area / (perimeter**2) if perimeter > 0 else 0\n",
    "            \n",
    "            # Classify by size\n",
    "            if area > 0.1:\n",
    "                category = 'Large'\n",
    "            elif area > 0.05:\n",
    "                category = 'Medium'\n",
    "            else:\n",
    "                category = 'Small'\n",
    "            \n",
    "            # Create feature\n",
    "            feature = {\n",
    "                'geometry': {\n",
    "                    'type': 'Polygon',\n",
    "                    'coordinates': [list(poly.exterior.coords)]\n",
    "                },\n",
    "                'properties': {\n",
    "                    'id': i + 1,\n",
    "                    'area': round(area, 6),\n",
    "                    'perimeter': round(perimeter, 6),\n",
    "                    'compactness': round(compactness, 4),\n",
    "                    'category': category\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            shp.write(feature)\n",
    "    \n",
    "    return len(polygons)\n",
    "\n",
    "# Create shapefile\n",
    "shapefile_path = output_dir / 'pattern_polygons.shp'\n",
    "features_written = create_shapefile_fiona(selected_polygons, shapefile_path)\n",
    "\n",
    "print(f\"Shapefile created: {shapefile_path}\")\n",
    "print(f\"Features written: {features_written}\")\n",
    "\n",
    "# List all shapefile components\n",
    "shapefile_files = list(output_dir.glob('pattern_polygons.*'))\n",
    "total_size = 0\n",
    "print(f\"\\nShapefile components:\")\n",
    "for file_path in sorted(shapefile_files):\n",
    "    size_kb = os.path.getsize(file_path) / 1024\n",
    "    total_size += size_kb\n",
    "    print(f\"  {file_path.name:20s} {size_kb:6.1f} KB\")\n",
    "print(f\"  {'Total:':20s} {total_size:6.1f} KB\")\n",
    "\n",
    "# Verify shapefile by reading it back\n",
    "print(f\"\\nVerifying shapefile:\")\n",
    "with fiona.open(shapefile_path) as shp:\n",
    "    print(f\"  Driver: {shp.driver}\")\n",
    "    print(f\"  CRS: {shp.crs}\")\n",
    "    print(f\"  Schema: {shp.schema}\")\n",
    "    print(f\"  Feature count: {len(shp)}\")\n",
    "    print(f\"  Bounds: {shp.bounds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🐼 GeoPandas Analysis & Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load shapefile with GeoPandas for analysis\n",
    "print(\"Loading shapefile with GeoPandas...\")\n",
    "\n",
    "# Read the shapefile\n",
    "gdf = gpd.read_file(shapefile_path)\n",
    "\n",
    "print(f\"GeoPandas GeoDataFrame loaded:\")\n",
    "print(f\"  Shape: {gdf.shape}\")\n",
    "print(f\"  CRS: {gdf.crs}\")\n",
    "print(f\"  Columns: {list(gdf.columns)}\")\n",
    "print(f\"  Geometry type: {gdf.geometry.type.iloc[0]}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(f\"\\nFirst 5 features:\")\n",
    "print(gdf.head())\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nSpatial statistics:\")\n",
    "print(f\"  Total area: {gdf['area'].sum():.4f} square degrees\")\n",
    "print(f\"  Mean area: {gdf['area'].mean():.4f} square degrees\")\n",
    "print(f\"  Area std: {gdf['area'].std():.4f} square degrees\")\n",
    "print(f\"  Mean compactness: {gdf['compactnes'].mean():.3f} (1.0 = perfect circle)\")\n",
    "\n",
    "# Category analysis\n",
    "print(f\"\\nCategory distribution:\")\n",
    "category_counts = gdf['category'].value_counts()\n",
    "for category, count in category_counts.items():\n",
    "\n",
    "    total_area = gdf[gdf['category'] == category]['area'].sum()\n",
    "    print(f\"  {category:6s}: {count:3d} features, {total_area:.4f} total area\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeoPandas spatial operations\n",
    "print(\"Performing GeoPandas spatial operations...\")\n",
    "\n",
    "# 1. Buffer operations\n",
    "print(\"\\n1. Creating buffers...\")\n",
    "buffer_distance = 0.1  # degrees\n",
    "gdf['geometry_buffered'] = gdf.geometry.buffer(buffer_distance)\n",
    "\n",
    "# Calculate buffer areas\n",
    "gdf['buffer_area'] = gdf['geometry_buffered'].area\n",
    "gdf['buffer_expansion'] = gdf['buffer_area'] / gdf['area']\n",
    "\n",
    "print(f\"  Buffer distance: {buffer_distance}°\")\n",
    "print(f\"  Mean area expansion: {gdf['buffer_expansion'].mean():.2f}x\")\n",
    "\n",
    "# 2. Centroid calculation\n",
    "print(\"\\n2. Calculating centroids...\")\n",
    "gdf['centroid'] = gdf.geometry.centroid\n",
    "gdf['centroid_x'] = gdf['centroid'].x\n",
    "gdf['centroid_y'] = gdf['centroid'].y\n",
    "\n",
    "print(f\"  Centroid longitude range: {gdf['centroid_x'].min():.3f} to {gdf['centroid_x'].max():.3f}\")\n",
    "print(f\"  Centroid latitude range: {gdf['centroid_y'].min():.3f} to {gdf['centroid_y'].max():.3f}\")\n",
    "\n",
    "# 3. Spatial relationships\n",
    "print(\"\\n3. Analyzing spatial relationships...\")\n",
    "\n",
    "# Find the largest polygon for spatial queries\n",
    "largest_poly_idx = gdf['area'].idxmax()\n",
    "largest_poly = gdf.loc[largest_poly_idx]\n",
    "\n",
    "print(f\"  Largest polygon: ID {largest_poly['id']}, area {largest_poly['area']:.4f}\")\n",
    "\n",
    "# Find polygons within buffer of largest polygon\n",
    "largest_buffered = largest_poly.geometry.buffer(0.5)\n",
    "within_buffer = gdf.geometry.within(largest_buffered)\n",
    "nearby_polygons = gdf[within_buffer]\n",
    "\n",
    "print(f\"  Polygons within 0.5° of largest: {len(nearby_polygons)}\")\n",
    "\n",
    "# Calculate distances to largest polygon centroid\n",
    "largest_centroid = largest_poly.geometry.centroid\n",
    "gdf['dist_to_largest'] = gdf['centroid'].distance(largest_centroid)\n",
    "\n",
    "print(f\"  Mean distance to largest polygon: {gdf['dist_to_largest'].mean():.3f}°\")\n",
    "print(f\"  Max distance to largest polygon: {gdf['dist_to_largest'].max():.3f}°\")\n",
    "\n",
    "# 4. Spatial joins and aggregation\n",
    "print(\"\\n4. Spatial aggregation...\")\n",
    "\n",
    "# Create a coarse grid for aggregation\n",
    "grid_size = 1.0  # degrees\n",
    "lon_min, lat_min, lon_max, lat_max = gdf.total_bounds\n",
    "\n",
    "# Create grid polygons\n",
    "grid_polygons = []\n",
    "grid_ids = []\n",
    "grid_id = 0\n",
    "\n",
    "for lon in np.arange(lon_min, lon_max, grid_size):\n",
    "    for lat in np.arange(lat_min, lat_max, grid_size):\n",
    "        grid_poly = Polygon([\n",
    "            (lon, lat),\n",
    "            (lon + grid_size, lat),\n",
    "            (lon + grid_size, lat + grid_size),\n",
    "            (lon, lat + grid_size),\n",
    "            (lon, lat)\n",
    "        ])\n",
    "        grid_polygons.append(grid_poly)\n",
    "        grid_ids.append(grid_id)\n",
    "        grid_id += 1\n",
    "\n",
    "# Create grid GeoDataFrame\n",
    "grid_gdf = gpd.GeoDataFrame({\n",
    "    'grid_id': grid_ids,\n",
    "    'geometry': grid_polygons\n",
    "}, crs=gdf.crs)\n",
    "\n",
    "# Spatial join: assign each polygon to a grid cell\n",
    "joined = gpd.sjoin(gdf, grid_gdf, how='left', predicate='within')\n",
    "\n",
    "# Aggregate by grid cell\n",
    "grid_stats = joined.groupby('grid_id').agg({\n",
    "    'area': ['count', 'sum', 'mean'],\n",
    "    'compactnes': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "print(f\"  Created {len(grid_gdf)} grid cells of {grid_size}° × {grid_size}°\")\n",
    "print(f\"  Grid cells with polygons: {len(grid_stats)}\")\n",
    "print(f\"  Max polygons per cell: {grid_stats[('area', 'count')].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced GeoPandas operations\n",
    "print(\"Advanced GeoPandas operations...\")\n",
    "\n",
    "# 5. Dissolve operation (union polygons by category)\n",
    "print(\"\\n5. Dissolving polygons by category...\")\n",
    "dissolved = gdf.dissolve(by='category', aggfunc={\n",
    "    'area': 'sum',\n",
    "    'perimeter': 'sum',\n",
    "    'id': 'count'\n",
    "})\n",
    "\n",
    "dissolved = dissolved.rename(columns={'id': 'polygon_count'})\n",
    "print(\"Dissolved polygons by category:\")\n",
    "print(dissolved[['area', 'perimeter', 'polygon_count']])\n",
    "\n",
    "# 6. Overlay operations\n",
    "print(\"\\n6. Overlay operations...\")\n",
    "\n",
    "# Create a circular area of interest\n",
    "center_point = Point(-7.5, 42.5)\n",
    "aoi_circle = center_point.buffer(1.0)  # 1 degree radius\n",
    "aoi_gdf = gpd.GeoDataFrame([1], geometry=[aoi_circle], crs=gdf.crs, columns=['aoi_id'])\n",
    "\n",
    "# Intersection with area of interest\n",
    "intersection = gpd.overlay(gdf, aoi_gdf, how='intersection')\n",
    "print(f\"  Original polygons: {len(gdf)}\")\n",
    "print(f\"  Polygons intersecting AOI: {len(intersection)}\")\n",
    "print(f\"  Total intersection area: {intersection.geometry.area.sum():.4f}°²\")\n",
    "\n",
    "# 7. Convex hull operations\n",
    "print(\"\\n7. Convex hulls...\")\n",
    "gdf['convex_hull'] = gdf.geometry.convex_hull\n",
    "gdf['convex_area'] = gdf['convex_hull'].area\n",
    "gdf['convexity'] = gdf['area'] / gdf['convex_area']\n",
    "\n",
    "print(f\"  Mean convexity: {gdf['convexity'].mean():.3f} (1.0 = already convex)\")\n",
    "print(f\"  Most complex polygon convexity: {gdf['convexity'].min():.3f}\")\n",
    "\n",
    "# 8. Nearest neighbor analysis\n",
    "print(\"\\n8. Nearest neighbor distances...\")\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "# Calculate distance to nearest neighbor for each polygon\n",
    "nearest_distances = []\n",
    "for i, poly in gdf.iterrows():\n",
    "    distances = []\n",
    "    for j, other_poly in gdf.iterrows():\n",
    "        if i != j:\n",
    "            distances.append(poly.geometry.distance(other_poly.geometry))\n",
    "    nearest_distances.append(min(distances) if distances else np.nan)\n",
    "\n",
    "gdf['nearest_neighbor_dist'] = nearest_distances\n",
    "\n",
    "print(f\"  Mean nearest neighbor distance: {gdf['nearest_neighbor_dist'].mean():.4f}°\")\n",
    "print(f\"  Min nearest neighbor distance: {gdf['nearest_neighbor_dist'].min():.4f}°\")\n",
    "print(f\"  Max nearest neighbor distance: {gdf['nearest_neighbor_dist'].max():.4f}°\")\n",
    "\n",
    "# 9. Export enhanced dataset\n",
    "print(\"\\n9. Exporting enhanced dataset...\")\n",
    "enhanced_cols = ['id', 'area', 'perimeter', 'compactnes', 'category', \n",
    "                'centroid_x', 'centroid_y', 'dist_to_largest', 'convexity', \n",
    "                'nearest_neighbor_dist', 'geometry']\n",
    "\n",
    "enhanced_gdf = gdf[enhanced_cols].copy()\n",
    "enhanced_shapefile = output_dir / 'pattern_polygons_enhanced.shp'\n",
    "enhanced_gdf.to_file(enhanced_shapefile)\n",
    "\n",
    "print(f\"  Enhanced shapefile saved: {enhanced_shapefile}\")\n",
    "print(f\"  Columns: {len(enhanced_cols)}\")\n",
    "print(f\"  Features: {len(enhanced_gdf)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Visualization & Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive visualization of results\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 14))\n",
    "\n",
    "# 1. Original pattern with extracted polygons\n",
    "axes[0,0].imshow(pattern_data, cmap='viridis', extent=bounds, aspect='equal', alpha=0.7)\n",
    "gdf.plot(ax=axes[0,0], facecolor='none', edgecolor='red', linewidth=1)\n",
    "axes[0,0].set_title('Original Pattern + Extracted Polygons')\n",
    "axes[0,0].set_xlabel('Longitude (°)')\n",
    "axes[0,0].set_ylabel('Latitude (°)')\n",
    "\n",
    "# 2. Polygons colored by category\n",
    "gdf.plot(column='category', ax=axes[0,1], cmap='Set1', legend=True)\n",
    "axes[0,1].set_title('Polygons by Size Category')\n",
    "axes[0,1].set_xlabel('Longitude (°)')\n",
    "axes[0,1].set_ylabel('Latitude (°)')\n",
    "\n",
    "# 3. Polygons colored by area\n",
    "gdf.plot(column='area', ax=axes[0,2], cmap='plasma', legend=True)\n",
    "axes[0,2].set_title('Polygons by Area')\n",
    "axes[0,2].set_xlabel('Longitude (°)')\n",
    "axes[0,2].set_ylabel('Latitude (°)')\n",
    "\n",
    "# 4. Buffered polygons\n",
    "gdf.set_geometry('geometry_buffered').plot(ax=axes[1,0], alpha=0.5, color='lightblue')\n",
    "gdf.plot(ax=axes[1,0], color='darkblue', alpha=0.8)\n",
    "axes[1,0].set_title('Original + Buffered Polygons')\n",
    "axes[1,0].set_xlabel('Longitude (°)')\n",
    "axes[1,0].set_ylabel('Latitude (°)')\n",
    "\n",
    "# 5. Centroids with distance to largest\n",
    "gdf.plot(ax=axes[1,1], color='lightgray', alpha=0.5)\n",
    "gdf.set_geometry('centroid').plot(column='dist_to_largest', ax=axes[1,1], \n",
    "                                 cmap='coolwarm', legend=True, markersize=50)\n",
    "# Highlight largest polygon\n",
    "gdf.loc[[largest_poly_idx]].plot(ax=axes[1,1], color='red', edgecolor='black', linewidth=2)\n",
    "axes[1,1].set_title('Distance to Largest Polygon')\n",
    "axes[1,1].set_xlabel('Longitude (°)')\n",
    "axes[1,1].set_ylabel('Latitude (°)')\n",
    "\n",
    "# 6. Dissolved polygons by category\n",
    "dissolved.plot(column='polygon_count', ax=axes[1,2], cmap='viridis', \n",
    "              legend=True, alpha=0.8, edgecolor='black')\n",
    "axes[1,2].set_title('Dissolved Polygons by Category')\n",
    "axes[1,2].set_xlabel('Longitude (°)')\n",
    "axes[1,2].set_ylabel('Latitude (°)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional analysis plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Area distribution histogram\n",
    "axes[0,0].hist(gdf['area'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_xlabel('Area (square degrees)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].set_title('Polygon Area Distribution')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Compactness vs Area scatter\n",
    "scatter = axes[0,1].scatter(gdf['area'], gdf['compactnes'], \n",
    "                           c=gdf['perimeter'], cmap='plasma', alpha=0.7)\n",
    "axes[0,1].set_xlabel('Area (square degrees)')\n",
    "axes[0,1].set_ylabel('Compactness')\n",
    "axes[0,1].set_title('Area vs Compactness (colored by perimeter)')\n",
    "plt.colorbar(scatter, ax=axes[0,1], label='Perimeter')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Nearest neighbor distances\n",
    "axes[1,0].hist(gdf['nearest_neighbor_dist'], bins=15, alpha=0.7, \n",
    "              color='orange', edgecolor='black')\n",
    "axes[1,0].set_xlabel('Nearest Neighbor Distance (degrees)')\n",
    "axes[1,0].set_ylabel('Frequency')\n",
    "axes[1,0].set_title('Nearest Neighbor Distance Distribution')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Category statistics\n",
    "category_areas = [gdf[gdf['category'] == cat]['area'].values for cat in gdf['category'].unique()]\n",
    "axes[1,1].boxplot(category_areas, labels=gdf['category'].unique())\n",
    "axes[1,1].set_ylabel('Area (square degrees)')\n",
    "axes[1,1].set_title('Area Distribution by Category')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔄 Format Conversions & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to different vector formats\n",
    "print(\"Exporting to different vector formats...\")\n",
    "\n",
    "export_formats = {\n",
    "    'GeoJSON': {'driver': 'GeoJSON', 'ext': '.geojson'},\n",
    "    'KML': {'driver': 'KML', 'ext': '.kml'},\n",
    "    'GeoPackage': {'driver': 'GPKG', 'ext': '.gpkg'},\n",
    "    'PostGIS_SQL': {'driver': 'PostgreSQL', 'ext': '.sql'}  # SQL dump\n",
    "}\n",
    "\n",
    "export_results = {}\n",
    "\n",
    "# Prepare simplified dataset for export\n",
    "export_gdf = gdf[['id', 'area', 'perimeter', 'compactnes', 'category', 'geometry']].copy()\n",
    "\n",
    "for format_name, format_config in export_formats.items():\n",
    "    try:\n",
    "        output_path = output_dir / f'pattern_polygons{format_config[\"ext\"]}'\n",
    "        \n",
    "        if format_name == 'PostGIS_SQL':\n",
    "            # Special handling for SQL export\n",
    "            continue  # Skip for now (requires PostGIS setup)\n",
    "        \n",
    "        export_gdf.to_file(output_path, driver=format_config['driver'])\n",
    "        file_size = os.path.getsize(output_path) / 1024\n",
    "        \n",
    "        export_results[format_name] = {\n",
    "            'path': output_path,\n",
    "            'size_kb': file_size,\n",
    "            'driver': format_config['driver']\n",
    "        }\n",
    "        \n",
    "        print(f\"{format_name:12s}: {file_size:7.1f} KB - {output_path.name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{format_name:12s}: FAILED - {e}\")\n",
    "\n",
    "# Create summary statistics export\n",
    "print(\"\\nExporting summary statistics...\")\n",
    "\n",
    "# Summary table\n",
    "summary_stats = {\n",
    "    'total_polygons': len(gdf),\n",
    "    'total_area': gdf['area'].sum(),\n",
    "    'mean_area': gdf['area'].mean(),\n",
    "    'largest_polygon_area': gdf['area'].max(),\n",
    "    'smallest_polygon_area': gdf['area'].min(),\n",
    "    'mean_compactness': gdf['compactnes'].mean(),\n",
    "    'category_distribution': dict(gdf['category'].value_counts()),\n",
    "    'mean_nearest_neighbor_dist': gdf['nearest_neighbor_dist'].mean(),\n",
    "    'spatial_extent': {\n",
    "        'lon_min': float(gdf.bounds['minx'].min()),\n",
    "        'lon_max': float(gdf.bounds['maxx'].max()),\n",
    "        'lat_min': float(gdf.bounds['miny'].min()),\n",
    "        'lat_max': float(gdf.bounds['maxy'].max())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Export to JSON\n",
    "import json\n",
    "with open(output_dir / 'polygon_analysis_summary.json', 'w') as f:\n",
    "    json.dump(summary_stats, f, indent=2, default=str)\n",
    "\n",
    "# Export detailed statistics to CSV\n",
    "detailed_stats = gdf[['id', 'area', 'perimeter', 'compactnes', 'category', \n",
    "                     'centroid_x', 'centroid_y', 'dist_to_largest', 'convexity',\n",
    "                     'nearest_neighbor_dist']].copy()\n",
    "detailed_stats.to_csv(output_dir / 'polygon_detailed_stats.csv', index=False)\n",
    "\n",
    "print(f\"  Summary JSON: polygon_analysis_summary.json\")\n",
    "print(f\"  Detailed CSV: polygon_detailed_stats.csv\")\n",
    "\n",
    "# Format comparison\n",
    "if export_results:\n",
    "    print(f\"\\nFormat size comparison:\")\n",
    "    sorted_formats = sorted(export_results.items(), key=lambda x: x[1]['size_kb'])\n",
    "    smallest_size = sorted_formats[0][1]['size_kb']\n",
    "    \n",
    "    for format_name, info in sorted_formats:\n",
    "        ratio = info['size_kb'] / smallest_size\n",
    "        print(f\"  {format_name:12s}: {info['size_kb']:7.1f} KB ({ratio:4.1f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive workflow summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"            VECTOR GEOSPATIAL WORKFLOW SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# File inventory\n",
    "print(f\"\\n📁 Generated Files:\")\n",
    "all_files = list(output_dir.glob('*'))\n",
    "total_size = 0\n",
    "\n",
    "file_categories = {\n",
    "    'Shapefiles': [],\n",
    "    'Other Formats': [],\n",
    "    'Analysis': []\n",
    "}\n",
    "\n",
    "for file_path in sorted(all_files):\n",
    "    if file_path.is_file():\n",
    "        size_kb = os.path.getsize(file_path) / 1024\n",
    "        total_size += size_kb\n",
    "        \n",
    "        if file_path.suffix in ['.shp', '.shx', '.dbf', '.prj', '.cpg']:\n",
    "            file_categories['Shapefiles'].append((file_path.name, size_kb))\n",
    "        elif file_path.suffix in ['.geojson', '.kml', '.gpkg']:\n",
    "            file_categories['Other Formats'].append((file_path.name, size_kb))\n",
    "        else:\n",
    "            file_categories['Analysis'].append((file_path.name, size_kb))\n",
    "\n",
    "for category, files in file_categories.items():\n",
    "    if files:\n",
    "        print(f\"\\n  {category}:\")\n",
    "        for name, size in files:\n",
    "            print(f\"    {name:35s} {size:6.1f} KB\")\n",
    "\n",
    "print(f\"\\n  {'Total:':37s} {total_size:6.1f} KB\")\n",
    "\n",
    "# Workflow steps\n",
    "print(f\"\\n⚡ Workflow Steps Completed:\")\n",
    "print(f\"  ✅ Created 2D pattern array ({pattern_data.shape[1]}×{pattern_data.shape[0]} pixels)\")\n",
    "print(f\"  ✅ Applied threshold (>{0.7}) and extracted {len(selected_polygons)} polygons\")\n",
    "print(f\"  ✅ Created shapefile with Fiona (low-level vector I/O)\")\n",
    "print(f\"  ✅ Loaded data with GeoPandas for spatial analysis\")\n",
    "print(f\"  ✅ Performed {8} different spatial operations\")\n",
    "print(f\"  ✅ Exported to {len(export_results)} different vector formats\")\n",
    "print(f\"  ✅ Generated comprehensive visualizations and statistics\")\n",
    "\n",
    "# Key transformations\n",
    "print(f\"\\n🔄 Key Transformations:\")\n",
    "print(f\"  Raster → Vector: {pattern_data.size:,} pixels → {len(selected_polygons)} polygons\")\n",
    "print(f\"  Threshold applied: Values > {0.7} ({high_value_pixels/total_pixels*100:.1f}% of pixels)\")\n",
    "print(f\"  Spatial analysis: {len(enhanced_cols)} attributes per polygon\")\n",
    "print(f\"  Format diversity: Shapefile, GeoJSON, KML, GeoPackage\")\n",
    "\n",
    "# Spatial statistics\n",
    "print(f\"\\n📊 Spatial Analysis Results:\")\n",
    "print(f\"  Total polygon area: {gdf['area'].sum():.4f} square degrees\")\n",
    "print(f\"  Largest polygon: {gdf['area'].max():.4f} square degrees\")\n",
    "print(f\"  Mean compactness: {gdf['compactnes'].mean():.3f} (circle = 1.0)\")\n",
    "print(f\"  Category breakdown: {dict(gdf['category'].value_counts())}\")\n",
    "print(f\"  Mean nearest neighbor: {gdf['nearest_neighbor_dist'].mean():.4f}°\")\n",
    "print(f\"  Spatial extent: {gdf.total_bounds}\")\n",
    "\n",
    "# Library capabilities demonstrated\n",
    "print(f\"\\n🚀 Library Capabilities Demonstrated:\")\n",
    "print(f\"\\n  Fiona (Low-level I/O):\")\n",
    "print(f\"    • Direct shapefile creation with custom schema\")\n",
    "print(f\"    • Metadata and attribute handling\")\n",
    "print(f\"    • Format validation and verification\")\n",
    "\n",
    "print(f\"\\n  Shapely (Geometry Operations):\")\n",
    "print(f\"    • Polygon creation from coordinates\")\n",
    "print(f\"    • Buffer operations and geometric calculations\")\n",
    "print(f\"    • Convex hulls and spatial relationships\")\n",
    "print(f\"    • Distance calculations and validity checks\")\n",
    "\n",
    "print(f\"\\n  GeoPandas (High-level Analysis):\")\n",
    "print(f\"    • Spatial joins and overlay operations\")\n",
    "print(f\"    • Dissolve and aggregation by attributes\")\n",
    "print(f\"    • Centroid calculation and coordinate extraction\")\n",
    "print(f\"    • Multi-format export capabilities\")\n",
    "print(f\"    • Statistical analysis and visualization\")\n",
    "\n",
    "print(f\"\\n🎯 Practical Applications:\")\n",
    "print(f\"  • Satellite imagery segmentation → vector features\")\n",
    "print(f\"  • Environmental monitoring (water bodies, deforestation)\")\n",
    "print(f\"  • Urban planning (building footprints, land use)\")\n",
    "print(f\"  • Ecological studies (habitat mapping, species distribution)\")\n",
    "print(f\"  • Climate analysis (precipitation zones, temperature regions)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧹 Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional cleanup\n",
    "cleanup_files = input(\"Remove all generated files? (y/N): \").lower().startswith('y')\n",
    "\n",
    "if cleanup_files:\n",
    "    import shutil\n",
    "    if output_dir.exists():\n",
    "        shutil.rmtree(output_dir)\n",
    "        print(\"✅ All output files removed\")\n",
    "else:\n",
    "    print(f\"💾 Files preserved in '{output_dir}/' directory\")\n",
    "    print(f\"   Total: {len(all_files)} files, {total_size:.1f} KB\")\n",
    "    print(f\"   Key files: pattern_polygons.shp, pattern_polygons_enhanced.shp\")\n",
    "    # print(f\"   Formats: {', '.join([f'{k} ({v['ext']})' for k, v in export_formats.items() if k in export_results])}\")\n",
    "\n",
    "print(f\"\\n🎉 Vector geospatial tutorial completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 Quick Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import html\n",
    "\n",
    "SECTIONS = [\n",
    "  (\"Fiona — Low-level I/O\", r\"\"\"import fiona\n",
    "# Write Shapefile\n",
    "with fiona.open('file.shp', 'w', driver='ESRI Shapefile',\n",
    "                schema=schema, crs='EPSG:4326') as shp:\n",
    "    shp.write({'geometry': geom_dict, 'properties': props})\n",
    "\n",
    "# Read features\n",
    "with fiona.open('file.shp') as shp:\n",
    "    for feature in shp:\n",
    "        geom  = feature['geometry']\n",
    "        props = feature['properties']\"\"\"),\n",
    "\n",
    "  (\"Shapely — Geometry Ops\", r\"\"\"from shapely.geometry import Point, Polygon, MultiPolygon\n",
    "poly  = Polygon([(x1, y1), (x2, y2), ...])\n",
    "buff  = poly.buffer(distance)\n",
    "area  = poly.area\n",
    "cent  = poly.centroid\n",
    "inter = poly1.intersection(poly2)\n",
    "inside = poly1.within(poly2)\"\"\"),\n",
    "\n",
    "  (\"GeoPandas — High-level Analysis\", r\"\"\"import geopandas as gpd\n",
    "gdf = gpd.read_file('file.shp')     # Read\n",
    "gdf.to_file('output.geojson')       # Write\n",
    "\n",
    "gdf.plot(column='attr', cmap='viridis')  # Quick viz\n",
    "buff = gdf.buffer(100)                   # Buffer all\n",
    "cent = gdf.centroid                      # Centroids\n",
    "diss = gdf.dissolve(by='attr')           # Dissolve\n",
    "\n",
    "# Spatial ops\n",
    "joined  = gpd.sjoin(gdf1, gdf2)                 # Spatial join\n",
    "overlay = gpd.overlay(gdf1, gdf2, how='intersection')\"\"\"),\n",
    "\n",
    "  (\"Raster → Vector (polygonize)\", r\"\"\"from rasterio.features import shapes\n",
    "from rasterio.transform import from_bounds\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "transform = from_bounds(*bounds, width, height)\n",
    "for geom, value in shapes(binary_array, transform=transform):\n",
    "    if value == 1:\n",
    "        polygon = Polygon(geom['coordinates'][0])\"\"\"),\n",
    "\n",
    "  (\"Common Spatial Analysis\", r\"\"\"gdf['area']     = gdf.geometry.area\n",
    "gdf['length']   = gdf.geometry.length\n",
    "gdf['centroid'] = gdf.geometry.centroid\n",
    "gdf['bounds']   = gdf.bounds               # bbox per row\n",
    "dist_series     = gdf.distance(point)      # distance to point\n",
    "within_mask     = gdf.within(polygon)      # point-in-polygon\"\"\"),\n",
    "\n",
    "  (\"Export Formats\", r\"\"\"gdf.to_file('output.shp')                        # Shapefile\n",
    "gdf.to_file('output.geojson', driver='GeoJSON')\n",
    "gdf.to_file('output.kml',     driver='KML')\n",
    "gdf.to_file('output.gpkg',    driver='GPKG')\"\"\"),\n",
    "]\n",
    "\n",
    "BEST_PRACTICES = [\n",
    "  \"Pick the right CRS for measurement vs web maps (project to meters for areas/lengths).\",\n",
    "  \"Validate & fix geometries (e.g., .buffer(0) or shapely.make_valid) before overlays.\",\n",
    "  \"Handle MultiPolygons / MultiLines explicitly when summarizing.\",\n",
    "  \"Choose formats wisely (GeoPackage for rich, Shapefile for legacy, GeoJSON for web).\",\n",
    "  \"Preserve metadata and set driver/CRS on write.\",\n",
    "]\n",
    "\n",
    "def section_html(title, code):\n",
    "    esc = html.escape(code)\n",
    "    return f\"\"\"\n",
    "    <section class=\"vsec\">\n",
    "      <div class=\"vsec-head\">\n",
    "        <h3>🧭 {html.escape(title)}</h3>\n",
    "        <button class=\"copy\" onclick=\"navigator.clipboard.writeText(this.parentElement.nextElementSibling.innerText)\">Copy</button>\n",
    "      </div>\n",
    "      <pre><code>{esc}</code></pre>\n",
    "    </section>\n",
    "    \"\"\"\n",
    "\n",
    "best_list = \"\".join(f\"<li>• {html.escape(x)}</li>\" for x in BEST_PRACTICES)\n",
    "\n",
    "html_block = f\"\"\"\n",
    "<style>\n",
    ":root {{\n",
    "  --bg: #0b132b;      /* deep night */\n",
    "  --panel: #0f1f3a;   /* marine slate */\n",
    "  --accent: #22d3ee;  /* cyan */\n",
    "  --accent2: #38bdf8; /* sky */\n",
    "  --text: #e6f1ff;\n",
    "  --muted: #9fb3c8;\n",
    "  --code-bg: #0a1a33;\n",
    "}}\n",
    ".v-wrap {{\n",
    "  font-family: Inter, ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif;\n",
    "  color: var(--text);\n",
    "  max-width: 980px;\n",
    "  margin: 10px 0 24px 0;\n",
    "}}\n",
    ".v-card {{\n",
    "  border-radius: 16px; overflow: hidden;\n",
    "  box-shadow: 0 10px 30px rgba(0,0,0,.25);\n",
    "  border: 1px solid rgba(255,255,255,.06);\n",
    "}}\n",
    ".v-hero {{\n",
    "  padding: 18px 20px;\n",
    "  background:\n",
    "    linear-gradient(135deg, rgba(34,211,238,.18), rgba(56,189,248,.12)),\n",
    "    radial-gradient(1000px 400px at 0% 0%, rgba(34,211,238,.18), transparent 60%),\n",
    "    radial-gradient(800px 400px at 100% 0%, rgba(56,189,248,.18), transparent 60%),\n",
    "    var(--bg);\n",
    "  border-bottom: 1px solid rgba(255,255,255,.07);\n",
    "  display:flex; align-items:center; justify-content:space-between; gap:10px;\n",
    "}}\n",
    ".v-title {{ margin:0; font-size:22px; letter-spacing:.2px; }}\n",
    ".badge {{\n",
    "  font-size:12px; color:#052;\n",
    "  background: linear-gradient(90deg, #22d3ee 0%, #38bdf8 100%);\n",
    "  -webkit-background-clip: text; background-clip: text; color: transparent;\n",
    "  font-weight:700;\n",
    "}}\n",
    ".actions {{ display:flex; gap:8px; }}\n",
    ".btn {{\n",
    "  cursor:pointer; border:1px solid rgba(255,255,255,.18);\n",
    "  background: rgba(255,255,255,.06); color: var(--text);\n",
    "  padding:6px 10px; border-radius:10px; font-size:12px;\n",
    "}}\n",
    ".btn:hover {{ background: rgba(255,255,255,.12); }}\n",
    "\n",
    ".v-body {{ background: var(--panel); padding: 16px 18px; }}\n",
    ".grid {{\n",
    "  display:grid; grid-template-columns: repeat(auto-fit, minmax(280px, 1fr)); gap:14px;\n",
    "}}\n",
    ".vsec {{ background: var(--code-bg); border:1px solid rgba(255,255,255,.06); border-radius:12px; overflow:hidden; }}\n",
    ".vsec-head {{ display:flex; align-items:center; justify-content:space-between; padding:10px 12px; background: rgba(255,255,255,.03); }}\n",
    ".vsec h3 {{ margin:0; font-size:14px; color: var(--accent2); letter-spacing:.3px; }}\n",
    ".copy {{ all: unset; cursor:pointer; padding:4px 8px; border-radius:8px; border:1px solid rgba(255,255,255,.15); font-size:12px; color: var(--text); }}\n",
    ".copy:hover {{ background: rgba(255,255,255,.10); }}\n",
    "pre {{\n",
    "  margin:0; padding:12px; color:#e6f1ff; line-height:1.35; font-size:12.8px;\n",
    "  overflow:auto; white-space:pre; tab-size:2;\n",
    "}}\n",
    "code {{ font-family: ui-monospace, SFMono-Regular, Menlo, Consolas, \"Liberation Mono\", monospace; }}\n",
    ".note {{ margin-top: 14px; color: var(--muted); font-size:13px; }}\n",
    ".kicker {{\n",
    "  margin-top: 14px; padding:10px 12px; background: rgba(56,189,248,.08);\n",
    "  border:1px solid rgba(56,189,248,.25); border-radius:12px; font-size:13px;\n",
    "}}\n",
    "ul.best {{ margin:10px 0 0 0; padding-left: 18px; color: var(--text); }}\n",
    "</style>\n",
    "\n",
    "<div class=\"v-wrap\">\n",
    "  <div class=\"v-card\">\n",
    "    <div class=\"v-hero\">\n",
    "      <h2 class=\"v-title\">📍 Vector Geospatial Quick Reference\n",
    "        <span class=\"badge\">Fiona • Shapely • GeoPandas</span>\n",
    "      </h2>\n",
    "      <div class=\"actions\">\n",
    "        <button class=\"btn\" onclick=\"(async()=>{{await navigator.clipboard.writeText(document.querySelector('#vector-cheat').innerText)}})()\">Copy All</button>\n",
    "      </div>\n",
    "    </div>\n",
    "\n",
    "    <div class=\"v-body\" id=\"vector-cheat\">\n",
    "      <div class=\"grid\">\n",
    "        {''.join(section_html(t,c) for t,c in SECTIONS)}\n",
    "      </div>\n",
    "\n",
    "      <div class=\"kicker\">\n",
    "        <b>Best Practices</b>\n",
    "        <ul class=\"best\">\n",
    "          {best_list}\n",
    "        </ul>\n",
    "      </div>\n",
    "\n",
    "      <div class=\"note\">Master the vector stack: read/write with <b>Fiona</b>, compute with <b>Shapely</b>, analyze & plot with <b>GeoPandas</b>. Don’t forget CRS & geometry validity. 🗺️</div>\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_block))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
