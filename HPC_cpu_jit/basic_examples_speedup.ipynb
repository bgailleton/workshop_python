{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Python Numerical Computing Speedup Comparison\n",
    "\n",
    "This notebook compares the performance of different Python libraries for numerical computing:\n",
    "\n",
    "- **NumPy**: Standard vectorized operations\n",
    "- **NumExpr**: Multi-threaded expression evaluation\n",
    "- **JAX**: JIT compilation with GPU support\n",
    "- **Numba**: JIT compilation for CPU (single-threaded and parallel)\n",
    "\n",
    "We'll use a simple but representative mathematical expression to demonstrate realistic speedups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numexpr as ne\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax import jit\n",
    "import numba\n",
    "from numba import njit, prange\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check available devices and settings\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "print(f\"Available devices: {jax.devices()}\")\n",
    "print(f\"NumExpr threads: {ne.nthreads}\")\n",
    "print(f\"NumPy threads: {np.__config__.show() if hasattr(np.__config__, 'show') else 'N/A'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup",
   "metadata": {},
   "source": [
    "## Test Setup\n",
    "\n",
    "We'll use a mathematical expression that's common in scientific computing:\n",
    "```\n",
    "result = sin(x) * exp(-y**2) + sqrt(abs(x * z)) - log1p(abs(y))\n",
    "```\n",
    "\n",
    "This expression includes:\n",
    "- Trigonometric functions (sin)\n",
    "- Exponential functions (exp)\n",
    "- Power operations (**2)\n",
    "- Element-wise operations (* +  -)\n",
    "- Mathematical functions (sqrt, log1p, abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test data - using same data for all methods to ensure fair comparison\n",
    "n = 10_000_000  # 10 million elements\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create arrays in float32 for consistency across all libraries\n",
    "x = np.random.randn(n).astype(np.float32)\n",
    "y = np.random.randn(n).astype(np.float32) \n",
    "z = np.random.randn(n).astype(np.float32)\n",
    "\n",
    "# JAX arrays (same data)\n",
    "x_jax = jnp.array(x)\n",
    "y_jax = jnp.array(y)\n",
    "z_jax = jnp.array(z)\n",
    "\n",
    "print(f\"Array size: {n:,} elements ({x.nbytes/1024**2:.1f} MB each)\")\n",
    "print(f\"Total memory: {3 * x.nbytes/1024**2:.1f} MB\")\n",
    "print(f\"Data type: {x.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "implementations",
   "metadata": {},
   "source": [
    "## Implementation of Each Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numpy_impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. NumPy implementation (baseline)\n",
    "def numpy_compute(x, y, z):\n",
    "    \"\"\"Standard NumPy vectorized operations\"\"\"\n",
    "    return np.sin(x) * np.exp(-y**2) + np.sqrt(np.abs(x * z)) - np.log1p(np.abs(y))\n",
    "\n",
    "print(\"NumPy implementation ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numexpr_impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. NumExpr implementation (multi-threaded evaluation)\n",
    "def numexpr_compute(x, y, z):\n",
    "    \"\"\"NumExpr multi-threaded expression evaluation\"\"\"\n",
    "    return ne.evaluate(\"sin(x) * exp(-y**2) + sqrt(abs(x * z)) - log1p(abs(y))\")\n",
    "\n",
    "print(\"NumExpr implementation ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jax_impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. JAX implementation (JIT compiled)\n",
    "def jax_compute(x, y, z):\n",
    "    \"\"\"JAX computation with XLA optimization\"\"\"\n",
    "    return jnp.sin(x) * jnp.exp(-y**2) + jnp.sqrt(jnp.abs(x * z)) - jnp.log1p(jnp.abs(y))\n",
    "\n",
    "# Create JIT-compiled version\n",
    "jax_compute_jit = jit(jax_compute)\n",
    "\n",
    "# Warmup JIT compilation\n",
    "print(\"Warming up JAX JIT compilation...\")\n",
    "for _ in range(3):\n",
    "    _ = jax_compute_jit(x_jax, y_jax, z_jax).block_until_ready()\n",
    "\n",
    "print(\"JAX implementation ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numba_impl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Numba implementations (JIT compiled for CPU)\n",
    "@njit\n",
    "def numba_compute(x, y, z):\n",
    "    \"\"\"Numba JIT compiled single-threaded\"\"\"\n",
    "    result = np.empty_like(x)\n",
    "    for i in range(len(x)):\n",
    "        result[i] = (np.sin(x[i]) * np.exp(-y[i]**2) + \n",
    "                    np.sqrt(np.abs(x[i] * z[i])) - \n",
    "                    np.log1p(np.abs(y[i])))\n",
    "    return result\n",
    "\n",
    "@njit(parallel=True)\n",
    "def numba_parallel_compute(x, y, z):\n",
    "    \"\"\"Numba JIT compiled multi-threaded with prange\"\"\"\n",
    "    result = np.empty_like(x)\n",
    "    for i in prange(len(x)):\n",
    "        result[i] = (np.sin(x[i]) * np.exp(-y[i]**2) + \n",
    "                    np.sqrt(np.abs(x[i] * z[i])) - \n",
    "                    np.log1p(np.abs(y[i])))\n",
    "    return result\n",
    "\n",
    "# Warmup Numba compilation\n",
    "print(\"Warming up Numba JIT compilation...\")\n",
    "small_x, small_y, small_z = x[:1000], y[:1000], z[:1000]\n",
    "_ = numba_compute(small_x, small_y, small_z)\n",
    "_ = numba_parallel_compute(small_x, small_y, small_z)\n",
    "\n",
    "print(\"Numba implementations ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "benchmark",
   "metadata": {},
   "source": [
    "## Performance Benchmark\n",
    "\n",
    "We'll run each method multiple times and report average performance with standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_method(func, name, *args, n_runs=5, **kwargs):\n",
    "    \"\"\"Benchmark a function with multiple runs\"\"\"\n",
    "    times = []\n",
    "    results = []\n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        start = time.perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        \n",
    "        # Handle JAX async execution\n",
    "        if hasattr(result, 'block_until_ready'):\n",
    "            result.block_until_ready()\n",
    "            \n",
    "        elapsed = time.perf_counter() - start\n",
    "        times.append(elapsed)\n",
    "        results.append(result)\n",
    "    \n",
    "    avg_time = np.mean(times)\n",
    "    std_time = np.std(times)\n",
    "    \n",
    "    print(f\"{name:<20}: {avg_time:.4f}s ± {std_time:.4f}s\")\n",
    "    return avg_time, std_time, results[-1]\n",
    "\n",
    "print(\"Running performance benchmark...\\n\")\n",
    "\n",
    "# Benchmark all methods\n",
    "numpy_time, numpy_std, numpy_result = benchmark_method(numpy_compute, \"NumPy\", x, y, z)\n",
    "numexpr_time, numexpr_std, numexpr_result = benchmark_method(numexpr_compute, \"NumExpr\", x, y, z)\n",
    "jax_time, jax_std, jax_result = benchmark_method(jax_compute_jit, \"JAX (JIT)\", x_jax, y_jax, z_jax)\n",
    "numba_time, numba_std, numba_result = benchmark_method(numba_compute, \"Numba (single)\", x, y, z)\n",
    "numba_par_time, numba_par_std, numba_par_result = benchmark_method(numba_parallel_compute, \"Numba (parallel)\", x, y, z)\n",
    "\n",
    "print(\"\\nBenchmark completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate speedups relative to NumPy\n",
    "print(\"\\n=== SPEEDUP ANALYSIS ===\")\n",
    "print(f\"{'Method':<20} {'Time (s)':<12} {'Speedup':<10} {'vs NumPy'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "methods = [\n",
    "    (\"NumPy\", numpy_time, numpy_std),\n",
    "    (\"NumExpr\", numexpr_time, numexpr_std),\n",
    "    (\"JAX (JIT)\", jax_time, jax_std),\n",
    "    (\"Numba (single)\", numba_time, numba_std),\n",
    "    (\"Numba (parallel)\", numba_par_time, numba_par_std)\n",
    "]\n",
    "\n",
    "for name, avg_time, std_time in methods:\n",
    "    speedup = numpy_time / avg_time\n",
    "    print(f\"{name:<20} {avg_time:.4f}±{std_time:.4f}  {speedup:.1f}x\")\n",
    "\n",
    "print(\"\\n=== NUMERICAL ACCURACY ===\")\n",
    "# Verify all methods produce the same results (within numerical precision)\n",
    "results = {\n",
    "    \"NumPy\": numpy_result,\n",
    "    \"NumExpr\": numexpr_result,\n",
    "    \"JAX\": np.array(jax_result),\n",
    "    \"Numba (single)\": numba_result,\n",
    "    \"Numba (parallel)\": numba_par_result\n",
    "}\n",
    "\n",
    "reference = numpy_result\n",
    "for name, result in results.items():\n",
    "    max_diff = np.max(np.abs(reference - result))\n",
    "    matches = np.allclose(reference, result, rtol=1e-6, atol=1e-7)\n",
    "    print(f\"{name:<20}: max diff = {max_diff:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Typical Performance Rankings:**\n",
    "\n",
    "1. **NumPy** (baseline): Standard vectorized operations, single-threaded\n",
    "2. **NumExpr** (2-4x faster): Multi-threaded evaluation, reduced memory allocation\n",
    "3. **JAX** (varies): GPU acceleration can give 5-20x speedup, CPU similar to NumPy\n",
    "4. **Numba single** (2-5x faster): JIT compilation eliminates Python overhead\n",
    "5. **Numba parallel** (4-10x faster): Multi-threaded JIT compilation\n",
    "\n",
    "**Key Insights:**\n",
    "- NumExpr excels for CPU-bound array operations\n",
    "- JAX shines with GPU acceleration\n",
    "- Numba provides excellent CPU performance with explicit parallelization\n",
    "- All methods produce numerically identical results\n",
    "- Performance gains depend on array size, operation complexity, and hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15851b5-4918-4beb-8b96-b177e21a2300",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.sqrt(np.random.rand(512*512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ecdde-8ec6-4034-b1e8-251910edc2de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187c0ddf-2681-47e9-9df1-c81565aa1e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyfastflow as pff\n",
    "\n",
    "noise = pff.noise.red_noise(4096,4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f11f8-cb39-4b52-a1de-a40d58e28ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad981c03-3df7-4c2a-9a78-f5f2666f4122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad792b6c-b16c-474c-b9ed-456d16255d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run(\"pff.noise.red_noise(4096,4096)\", sort='tottime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19d573-388c-4afc-ad6c-137f9777ad9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
