{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install NetCDF and related packages\n",
    "!pip install netCDF4 xarray numpy matplotlib cartopy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NetCDF Tutorial - Climate & Geoscience Data Standard\n",
    "\n",
    "**NetCDF** is the standard for climate and geoscience data:\n",
    "- **Self-describing**: Rich metadata following CF conventions\n",
    "- **Multidimensional**: Perfect for gridded data (time, lat, lon, level)\n",
    "- **Interoperable**: Works with all major climate tools\n",
    "- **Efficient**: Optimized for scientific array access patterns\n",
    "\n",
    "Perfect for: weather data, oceanography, satellite imagery, climate models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr  # Modern NetCDF interface\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"NetCDF4 version: {nc.__version__}\")\n",
    "print(f\"xarray version: {xr.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåç Creating Climate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate realistic climate dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "# Coordinate dimensions\n",
    "ntime = 365  # Daily data for 1 year\n",
    "nlat = 180   # 1-degree latitude grid\n",
    "nlon = 360   # 1-degree longitude grid\n",
    "nlevel = 10  # Pressure levels\n",
    "\n",
    "# Create coordinate arrays\n",
    "time_base = datetime(2023, 1, 1)\n",
    "times = [time_base + timedelta(days=i) for i in range(ntime)]\n",
    "time_numeric = nc.date2num(times, 'days since 1900-01-01', calendar='gregorian')\n",
    "\n",
    "latitudes = np.linspace(-89.5, 89.5, nlat)\n",
    "longitudes = np.linspace(-179.5, 179.5, nlon)\n",
    "pressure_levels = [1000, 925, 850, 700, 600, 500, 400, 300, 250, 200]  # hPa\n",
    "\n",
    "# Generate realistic temperature data\n",
    "# Base temperature with latitude gradient\n",
    "lat_grid, lon_grid = np.meshgrid(latitudes, longitudes, indexing='ij')\n",
    "base_temp = 30 - 0.6 * np.abs(lat_grid)  # Cooler at poles\n",
    "\n",
    "# Add seasonal cycle\n",
    "temp_data = np.zeros((ntime, nlat, nlon))\n",
    "for t in range(ntime):\n",
    "    day_of_year = t + 1\n",
    "    seasonal = 10 * np.cos(2 * np.pi * (day_of_year - 172) / 365)  # Peak in summer\n",
    "    # Different seasonal amplitude by latitude\n",
    "    seasonal_field = seasonal * (1 - 0.5 * np.abs(lat_grid) / 90)\n",
    "    # Hemisphere phase shift\n",
    "    seasonal_field[lat_grid < 0] *= -1\n",
    "    \n",
    "    temp_data[t, :, :] = base_temp + seasonal_field + np.random.normal(0, 2, (nlat, nlon))\n",
    "\n",
    "# Generate precipitation (more realistic pattern)\n",
    "precip_data = np.zeros((ntime, nlat, nlon))\n",
    "for t in range(ntime):\n",
    "    # ITCZ pattern\n",
    "    itcz_lat = 10 * np.sin(2 * np.pi * t / 365)\n",
    "    itcz_rain = 20 * np.exp(-((lat_grid - itcz_lat) / 10)**2)\n",
    "    \n",
    "    # Mid-latitude storm tracks\n",
    "    storm_rain = 5 * (np.exp(-((lat_grid - 45) / 15)**2) + np.exp(-((lat_grid + 45) / 15)**2))\n",
    "    \n",
    "    base_precip = itcz_rain + storm_rain\n",
    "    precip_data[t, :, :] = np.maximum(0, base_precip + np.random.exponential(2, (nlat, nlon)))\n",
    "\n",
    "# Generate 3D atmospheric data (temperature by pressure level)\n",
    "temp_3d = np.zeros((ntime, nlevel, nlat, nlon))\n",
    "for p, pres in enumerate(pressure_levels):\n",
    "    # Temperature decreases with altitude (roughly -6.5K/km)\n",
    "    # Using standard atmosphere approximation\n",
    "    altitude_km = 44.3 - 6.25 * np.log(pres / 1013.25)  # Approximate altitude\n",
    "    temp_offset = -6.5 * altitude_km  # Lapse rate\n",
    "    temp_3d[:, p, :, :] = temp_data + temp_offset\n",
    "\n",
    "print(f\"Generated climate data:\")\n",
    "print(f\"  2D Temperature: {temp_data.shape} (time, lat, lon)\")\n",
    "print(f\"  2D Precipitation: {precip_data.shape}\")\n",
    "print(f\"  3D Temperature: {temp_3d.shape} (time, level, lat, lon)\")\n",
    "print(f\"  Total size: {(temp_data.nbytes + precip_data.nbytes + temp_3d.nbytes)/1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Creating NetCDF with CF Conventions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'climate_data.nc'\n",
    "\n",
    "with nc.Dataset(filename, 'w', format='NETCDF4') as ncfile:\n",
    "    # Global attributes (CF convention)\n",
    "    ncfile.title = 'Synthetic Global Climate Data'\n",
    "    ncfile.institution = 'Python Climate Workshop'\n",
    "    ncfile.source = 'Synthetic data generated for demonstration'\n",
    "    ncfile.history = f'Created on {datetime.now().isoformat()}'\n",
    "    ncfile.Conventions = 'CF-1.8'\n",
    "    ncfile.comment = 'Educational dataset demonstrating NetCDF structure'\n",
    "    \n",
    "    # Create dimensions\n",
    "    ncfile.createDimension('time', ntime)\n",
    "    ncfile.createDimension('lat', nlat)\n",
    "    ncfile.createDimension('lon', nlon)\n",
    "    ncfile.createDimension('level', nlevel)\n",
    "    \n",
    "    # Coordinate variables\n",
    "    times_var = ncfile.createVariable('time', 'f8', ('time',))\n",
    "    times_var[:] = time_numeric\n",
    "    times_var.units = 'days since 1900-01-01'\n",
    "    times_var.calendar = 'gregorian'\n",
    "    times_var.long_name = 'time'\n",
    "    times_var.standard_name = 'time'\n",
    "    \n",
    "    lats_var = ncfile.createVariable('lat', 'f4', ('lat',))\n",
    "    lats_var[:] = latitudes\n",
    "    lats_var.units = 'degrees_north'\n",
    "    lats_var.long_name = 'latitude'\n",
    "    lats_var.standard_name = 'latitude'\n",
    "    \n",
    "    lons_var = ncfile.createVariable('lon', 'f4', ('lon',))\n",
    "    lons_var[:] = longitudes\n",
    "    lons_var.units = 'degrees_east'\n",
    "    lons_var.long_name = 'longitude'\n",
    "    lons_var.standard_name = 'longitude'\n",
    "    \n",
    "    levels_var = ncfile.createVariable('level', 'f4', ('level',))\n",
    "    levels_var[:] = pressure_levels\n",
    "    levels_var.units = 'hPa'\n",
    "    levels_var.long_name = 'pressure level'\n",
    "    levels_var.standard_name = 'air_pressure'\n",
    "    levels_var.positive = 'down'\n",
    "    \n",
    "    # Data variables (set fill_value at creation)\n",
    "    fv = np.float32(-999.0)\n",
    "\n",
    "    temp_var = ncfile.createVariable(\n",
    "        'temperature', 'f4', ('time', 'lat', 'lon'),\n",
    "        zlib=True, complevel=6, shuffle=True, fill_value=fv\n",
    "    )\n",
    "    temp_var[:] = temp_data.astype(np.float32)\n",
    "    temp_var.units = 'degrees_celsius'\n",
    "    temp_var.long_name = '2-meter air temperature'\n",
    "    temp_var.standard_name = 'air_temperature'\n",
    "    temp_var.cell_methods = 'time: mean'\n",
    "    \n",
    "    precip_var = ncfile.createVariable(\n",
    "        'precipitation', 'f4', ('time', 'lat', 'lon'),\n",
    "        zlib=True, complevel=6, shuffle=True, fill_value=fv\n",
    "    )\n",
    "    precip_var[:] = precip_data.astype(np.float32)\n",
    "    precip_var.units = 'mm/day'  # note: CF 'precipitation_flux' expects kg m-2 s-1\n",
    "    precip_var.long_name = 'daily precipitation'\n",
    "    precip_var.standard_name = 'precipitation_flux'\n",
    "    precip_var.cell_methods = 'time: sum'\n",
    "    \n",
    "    temp_3d_var = ncfile.createVariable(\n",
    "        'temperature_3d', 'f4', ('time', 'level', 'lat', 'lon'),\n",
    "        zlib=True, complevel=6, shuffle=True,\n",
    "        chunksizes=(10, 5, 45, 90), fill_value=fv\n",
    "    )\n",
    "    temp_3d_var[:] = temp_3d.astype(np.float32)\n",
    "    temp_3d_var.units = 'degrees_celsius'\n",
    "    temp_3d_var.long_name = 'air temperature at pressure levels'\n",
    "    temp_3d_var.standard_name = 'air_temperature'\n",
    "    temp_3d_var.coordinates = 'level lat lon'\n",
    "    \n",
    "    print(f\"NetCDF file created: {filename}\")\n",
    "    print(f\"Variables: {list(ncfile.variables.keys())}\")\n",
    "\n",
    "print(f\"File size: {os.path.getsize(filename)/1024**2:.1f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Reading NetCDF Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading with netCDF4 (low-level)\n",
    "print(\"Reading with netCDF4:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "with nc.Dataset(filename, 'r') as ncfile:\n",
    "    print(f\"Global attributes:\")\n",
    "    for attr in ncfile.ncattrs():\n",
    "        print(f\"  {attr}: {getattr(ncfile, attr)}\")\n",
    "    \n",
    "    print(f\"\\nDimensions:\")\n",
    "    for dim in ncfile.dimensions:\n",
    "        print(f\"  {dim}: {len(ncfile.dimensions[dim])}\")\n",
    "    \n",
    "    print(f\"\\nVariables:\")\n",
    "    for var in ncfile.variables:\n",
    "        v = ncfile.variables[var]\n",
    "        print(f\"  {var}: {v.shape} {v.dtype}\")\n",
    "        if hasattr(v, 'units'):\n",
    "            print(f\"    units: {v.units}\")\n",
    "    \n",
    "    # Read sample data\n",
    "    temp = ncfile.variables['temperature'][:]\n",
    "    lats = ncfile.variables['lat'][:]\n",
    "    lons = ncfile.variables['lon'][:]\n",
    "    times = ncfile.variables['time'][:]\n",
    "    \n",
    "    print(f\"\\nData ranges:\")\n",
    "    print(f\"  Temperature: {temp.min():.1f} to {temp.max():.1f} ¬∞C\")\n",
    "    print(f\"  Time range: {nc.num2date(times[0], ncfile.variables['time'].units)} to {nc.num2date(times[-1], ncfile.variables['time'].units)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading with xarray (modern approach)\n",
    "print(\"\\nReading with xarray:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "ds = xr.open_dataset(filename)\n",
    "print(ds)\n",
    "\n",
    "print(f\"\\nDataset info:\")\n",
    "print(f\"  Coordinates: {list(ds.coords)}\")\n",
    "print(f\"  Data variables: {list(ds.data_vars)}\")\n",
    "print(f\"  Global attrs: {len(ds.attrs)} attributes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è Visualizing Climate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the climate data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Global temperature map (annual mean)\n",
    "temp_annual = ds['temperature'].mean(dim='time')\n",
    "im1 = axes[0,0].imshow(temp_annual, extent=[-180, 180, -90, 90], \n",
    "                      cmap='RdYlBu_r', aspect='equal')\n",
    "axes[0,0].set_title('Annual Mean Temperature')\n",
    "axes[0,0].set_xlabel('Longitude')\n",
    "axes[0,0].set_ylabel('Latitude')\n",
    "plt.colorbar(im1, ax=axes[0,0], label='¬∞C')\n",
    "\n",
    "# Annual precipitation\n",
    "precip_annual = ds['precipitation'].mean(dim='time')\n",
    "im2 = axes[0,1].imshow(precip_annual, extent=[-180, 180, -90, 90], \n",
    "                      cmap='Blues', aspect='equal')\n",
    "axes[0,1].set_title('Annual Mean Precipitation')\n",
    "axes[0,1].set_xlabel('Longitude')\n",
    "axes[0,1].set_ylabel('Latitude')\n",
    "plt.colorbar(im2, ax=axes[0,1], label='mm/day')\n",
    "\n",
    "# Time series at specific location (e.g., New York: 40.7¬∞N, 74¬∞W)\n",
    "ny_temp = ds['temperature'].sel(lat=40.5, lon=-74, method='nearest')\n",
    "ny_precip = ds['precipitation'].sel(lat=40.5, lon=-74, method='nearest')\n",
    "\n",
    "ax3 = axes[1,0]\n",
    "ax3.plot(ny_temp.time, ny_temp, 'r-', linewidth=2, label='Temperature')\n",
    "ax3.set_xlabel('Time')\n",
    "ax3.set_ylabel('Temperature (¬∞C)', color='r')\n",
    "ax3.tick_params(axis='y', labelcolor='r')\n",
    "ax3.set_title('Time Series near New York')\n",
    "\n",
    "ax3_twin = ax3.twinx()\n",
    "ax3_twin.bar(ny_precip.time, ny_precip, alpha=0.6, color='blue', width=0.8, label='Precipitation')\n",
    "ax3_twin.set_ylabel('Precipitation (mm/day)', color='b')\n",
    "ax3_twin.tick_params(axis='y', labelcolor='b')\n",
    "\n",
    "# Vertical temperature profile (January average at equator)\n",
    "temp_profile = ds['temperature_3d'].isel(time=0).sel(lat=0, lon=0, method='nearest')\n",
    "axes[1,1].plot(temp_profile, temp_profile.level, 'g-', linewidth=2, marker='o')\n",
    "axes[1,1].set_xlabel('Temperature (¬∞C)')\n",
    "axes[1,1].set_ylabel('Pressure (hPa)')\n",
    "axes[1,1].set_title('Vertical Temperature Profile (Jan 1, Equator)')\n",
    "axes[1,1].invert_yaxis()  # Higher altitude at top\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Advanced NetCDF Analysis with xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate xarray's powerful analysis capabilities\n",
    "print(\"Advanced Climate Analysis with xarray:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. Seasonal climatology\n",
    "seasonal_temp = ds['temperature'].groupby('time.season').mean()\n",
    "print(f\"Seasonal climatology shape: {seasonal_temp.shape}\")\n",
    "\n",
    "# 2. Global averages\n",
    "# Weight by cosine of latitude for proper area averaging\n",
    "weights = np.cos(np.deg2rad(ds.lat))\n",
    "global_temp = (ds['temperature'] * weights).sum(dim=['lat', 'lon']) / weights.sum()\n",
    "\n",
    "# 3. Monthly anomalies\n",
    "monthly_clim = ds['temperature'].groupby('time.month').mean()\n",
    "monthly_anom = ds['temperature'].groupby('time.month') - monthly_clim\n",
    "\n",
    "# 4. Regional statistics\n",
    "# Select tropical region (30¬∞S to 30¬∞N)\n",
    "tropical = ds.sel(lat=slice(-30, 30))\n",
    "tropical_mean_temp = tropical['temperature'].mean(dim=['lat', 'lon'])\n",
    "\n",
    "print(f\"\\nAnalysis results:\")\n",
    "print(f\"  Global mean temperature: {float(global_temp.mean()):.1f} ¬∞C\")\n",
    "print(f\"  Tropical mean temperature: {float(tropical_mean_temp.mean()):.1f} ¬∞C\")\n",
    "print(f\"  Temperature range: {float(ds['temperature'].min()):.1f} to {float(ds['temperature'].max()):.1f} ¬∞C\")\n",
    "\n",
    "# Visualize analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Seasonal temperature differences\n",
    "season_diff = seasonal_temp.sel(season='JJA') - seasonal_temp.sel(season='DJF')\n",
    "im1 = axes[0,0].imshow(season_diff, extent=[-180, 180, -90, 90], \n",
    "                      cmap='RdBu_r', vmin=-20, vmax=20, aspect='equal')\n",
    "axes[0,0].set_title('Summer - Winter Temperature Difference')\n",
    "plt.colorbar(im1, ax=axes[0,0], label='¬∞C')\n",
    "\n",
    "# Global temperature time series\n",
    "axes[0,1].plot(global_temp.time, global_temp, 'b-', linewidth=2)\n",
    "axes[0,1].set_title('Global Mean Temperature')\n",
    "axes[0,1].set_ylabel('Temperature (¬∞C)')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly temperature anomaly at a point\n",
    "point_anom = monthly_anom.sel(lat=45, lon=0, method='nearest')\n",
    "axes[1,0].plot(point_anom.time, point_anom, 'r-', linewidth=1)\n",
    "axes[1,0].axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "axes[1,0].set_title('Monthly Temperature Anomalies (45¬∞N, 0¬∞E)')\n",
    "axes[1,0].set_ylabel('Anomaly (¬∞C)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Zonal mean temperature\n",
    "zonal_temp = ds['temperature'].mean(dim=['time', 'lon'])\n",
    "axes[1,1].plot(zonal_temp, zonal_temp.lat, 'g-', linewidth=2)\n",
    "axes[1,1].set_xlabel('Temperature (¬∞C)')\n",
    "axes[1,1].set_ylabel('Latitude')\n",
    "axes[1,1].set_title('Zonal Mean Temperature')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ NetCDF Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate chunking and compression strategies\n",
    "import os\n",
    "print(\"NetCDF Optimization Strategies:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Test different chunking strategies for time series data\n",
    "test_data = np.random.randn(365, 100, 100).astype(np.float32)\n",
    "\n",
    "strategies = {\n",
    "    'time_chunks': (50, 100, 100),    # Good for time series analysis\n",
    "    'spatial_chunks': (365, 25, 25),  # Good for spatial analysis  \n",
    "    'balanced': (30, 50, 50),         # Balanced approach\n",
    "    'auto': None                      # Let NetCDF decide\n",
    "}\n",
    "\n",
    "for name, chunks in strategies.items():\n",
    "    test_file = f'test_{name}.nc'\n",
    "    \n",
    "    with nc.Dataset(test_file, 'w', format='NETCDF4') as ncfile:\n",
    "        ncfile.createDimension('time', 365)\n",
    "        ncfile.createDimension('y', 100)\n",
    "        ncfile.createDimension('x', 100)\n",
    "        \n",
    "        if chunks:\n",
    "            var = ncfile.createVariable('data', 'f4', ('time', 'y', 'x'),\n",
    "                                       zlib=True, complevel=6, \n",
    "                                       chunksizes=chunks)\n",
    "        else:\n",
    "            var = ncfile.createVariable('data', 'f4', ('time', 'y', 'x'),\n",
    "                                       zlib=True, complevel=6)\n",
    "        var[:] = test_data\n",
    "    \n",
    "    file_size = os.path.getsize(test_file) / 1024**2\n",
    "    \n",
    "    # Test read performance\n",
    "    import time\n",
    "    with nc.Dataset(test_file, 'r') as ncfile:\n",
    "        start = time.time()\n",
    "        _ = ncfile.variables['data'][0, :, :]  # Read one time slice\n",
    "        spatial_time = time.time() - start\n",
    "        \n",
    "        start = time.time()\n",
    "        _ = ncfile.variables['data'][:, 50, 50]  # Read time series at point\n",
    "        temporal_time = time.time() - start\n",
    "    \n",
    "    print(f\"{name:15s}: {file_size:5.1f} MB | Spatial: {spatial_time:.3f}s | Temporal: {temporal_time:.3f}s\")\n",
    "    os.remove(test_file)\n",
    "\n",
    "print(f\"\\nüí° Chunking Guidelines:\")\n",
    "print(f\"   ‚Ä¢ Time-series analysis: Chunk along time dimension\")\n",
    "print(f\"   ‚Ä¢ Spatial analysis: Chunk spatially (lat/lon)\")\n",
    "print(f\"   ‚Ä¢ Balanced: Use moderate chunks for mixed access\")\n",
    "print(f\"   ‚Ä¢ File size: Compression effectiveness varies by chunk size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate NetCDF data export/conversion\n",
    "print(\"\\nData Export Options:\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "# Export to different formats using xarray\n",
    "sample_data = ds.isel(time=slice(0, 10))  # First 10 days\n",
    "\n",
    "# 1. Save subset as new NetCDF\n",
    "sample_data.to_netcdf('sample_data.nc')\n",
    "print(f\"NetCDF subset: {os.path.getsize('sample_data.nc')/1024:.1f} KB\")\n",
    "\n",
    "# 2. Export to CSV (for specific location)\n",
    "point_data = ds.sel(lat=40, lon=-74, method='nearest').to_dataframe()\n",
    "point_data.to_csv('point_timeseries.csv')\n",
    "print(f\"CSV export: {os.path.getsize('point_timeseries.csv')/1024:.1f} KB\")\n",
    "\n",
    "# 3. Convert to different NetCDF format\n",
    "sample_data.to_netcdf('sample_classic.nc', format='NETCDF3_CLASSIC')\n",
    "print(f\"NetCDF3 format: {os.path.getsize('sample_classic.nc')/1024:.1f} KB\")\n",
    "\n",
    "# Clean up\n",
    "for f in ['sample_data.nc', 'point_timeseries.csv', 'sample_classic.nc']:\n",
    "    if os.path.exists(f):\n",
    "        os.remove(f)\n",
    "\n",
    "print(f\"\\nüîÑ Integration Tips:\")\n",
    "print(f\"   ‚Ä¢ Use xarray for analysis, netCDF4 for low-level control\")\n",
    "print(f\"   ‚Ä¢ Follow CF conventions for metadata\")\n",
    "print(f\"   ‚Ä¢ Add comprehensive attributes and documentation\")\n",
    "print(f\"   ‚Ä¢ Use appropriate chunking for your access patterns\")\n",
    "print(f\"   ‚Ä¢ Enable compression for most scientific datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã NetCDF Quick Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "ds.close()\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "    print(f\"Cleaned up: {filename}\")\n",
    "\n",
    "reference = \"\"\"\n",
    "NETCDF QUICK REFERENCE:\n",
    "\n",
    "Creating NetCDF (netCDF4):\n",
    "  import netCDF4 as nc\n",
    "  with nc.Dataset('file.nc', 'w') as f:\n",
    "      f.createDimension('time', None)  # Unlimited\n",
    "      f.createDimension('lat', 180)\n",
    "      var = f.createVariable('temp', 'f4', ('time', 'lat', 'lon'),\n",
    "                            zlib=True, complevel=6)\n",
    "      var[:] = data\n",
    "      var.units = 'degrees_celsius'\n",
    "\n",
    "Reading NetCDF (xarray - recommended):\n",
    "  import xarray as xr\n",
    "  ds = xr.open_dataset('file.nc')\n",
    "  temp = ds['temperature']         # Access variable\n",
    "  subset = ds.sel(lat=45, lon=0)   # Select by coordinate\n",
    "  annual = ds.groupby('time.year').mean()  # Group operations\n",
    "\n",
    "CF Convention Attributes:\n",
    "  var.standard_name = 'air_temperature'     # CF standard name\n",
    "  var.long_name = 'Air Temperature'         # Descriptive name\n",
    "  var.units = 'degrees_celsius'             # Units string\n",
    "  var.coordinates = 'lat lon'               # Coordinate variables\n",
    "  var._FillValue = -999.0                   # Missing value\n",
    "\n",
    "Performance Optimization:\n",
    "  # Chunking for time-series access\n",
    "  chunksizes=(50, lat_size, lon_size)\n",
    "  \n",
    "  # Compression\n",
    "  zlib=True, complevel=6, shuffle=True\n",
    "  \n",
    "  # Data types\n",
    "  Use 'f4' instead of 'f8' when precision allows\n",
    "\n",
    "xarray Analysis Patterns:\n",
    "  ds.mean(dim='time')              # Temporal mean\n",
    "  ds.sel(lat=slice(-30, 30))       # Regional selection\n",
    "  ds.groupby('time.season').mean() # Seasonal climatology\n",
    "  ds.resample(time='1M').mean()    # Monthly resampling\n",
    "\n",
    "Best Practices:\n",
    "  ‚Ä¢ Follow CF conventions for interoperability\n",
    "  ‚Ä¢ Use descriptive variable and attribute names\n",
    "  ‚Ä¢ Include comprehensive metadata\n",
    "  ‚Ä¢ Choose appropriate chunking for access patterns\n",
    "  ‚Ä¢ Enable compression for most datasets\n",
    "  ‚Ä¢ Use unlimited time dimension for extensibility\n",
    "\"\"\"\n",
    "\n",
    "print(reference)\n",
    "print(\"\\nüåç NetCDF: The standard for climate and geoscience data! üì°\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
