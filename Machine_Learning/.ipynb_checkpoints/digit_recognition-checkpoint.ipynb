{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82224df4",
   "metadata": {},
   "source": [
    "# PyTorch + MNIST (Single Digit, Solid) — Robust Preproc + Augmentation + JupyterLab Canvas\n",
    "\n",
    "**Goal:** Train a small but **reliable** digit recognizer (0–9) that behaves well on tricky **7/9** and hand-drawn inputs.\n",
    "\n",
    "**What makes this version sturdier**\n",
    "- **Data augmentation** (rotations, shifts, shear) during training → more invariant features.  \n",
    "- **BatchNorm + Dropout** in the CNN → stable + less overfit.  \n",
    "- **Preprocessing for drawings** that mimics MNIST's centering: resize longest side to **20**, then **pad to 28×28**, and **center by mass**.  \n",
    "- Consistent **normalization** (MNIST mean/std) for both training and your canvas input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60280384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ▶️ Install (run once). ipycanvas = JupyterLab-friendly drawing widget.\n",
    "!pip -q install torch torchvision matplotlib pillow ipywidgets ipycanvas\n",
    "# In classic Notebook you may need: jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd0e1a1",
   "metadata": {},
   "source": [
    "## 0) Hyperparameters (safe knobs for the demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2382a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED       = 42\n",
    "TRAIN_SIZE = 40000\n",
    "VAL_SIZE   = 5000\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS     = 8\n",
    "LR         = 1e-3\n",
    "\n",
    "# Canvas UI\n",
    "CANVAS_INTERNAL = 224\n",
    "DISPLAY_PX      = 240\n",
    "BRUSH_INIT      = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ad0c20",
   "metadata": {},
   "source": [
    "## 1) Imports & basic setup — what happens here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d977d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from ipywidgets import VBox, HBox, Button, HTML, IntSlider, Layout\n",
    "from ipycanvas import Canvas\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10000e12",
   "metadata": {},
   "source": [
    "## 2) Dataset download + **augmentation** + normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63fc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_MEAN, MNIST_STD = 0.1307, 0.3081\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomAffine(\n",
    "        degrees=20, translate=(0.1, 0.1), shear=10, fill=0\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((MNIST_MEAN,), (MNIST_STD,)),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((MNIST_MEAN,), (MNIST_STD,)),\n",
    "])\n",
    "\n",
    "train_full = datasets.MNIST(root='./data', train=True, download=True, transform=train_tfms)\n",
    "test_full  = datasets.MNIST(root='./data', train=False, download=True, transform=val_tfms)\n",
    "\n",
    "rng = np.random.default_rng(SEED)\n",
    "idx_train = rng.choice(len(train_full), size=min(TRAIN_SIZE, len(train_full)), replace=False)\n",
    "idx_val   = rng.choice(len(test_full),  size=min(VAL_SIZE, len(test_full)), replace=False)\n",
    "\n",
    "train_ds = Subset(train_full, idx_train)\n",
    "val_ds   = Subset(test_full,  idx_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = next(iter(DataLoader(Subset(datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor()), idx_train), batch_size=6)))\n",
    "fig, axes = plt.subplots(1, 6, figsize=(9,2))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(xb[i,0].numpy(), cmap='gray'); ax.set_title(int(yb[i])); ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e9854e",
   "metadata": {},
   "source": [
    "## 3) Model architecture — small CNN, but sturdier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed14071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SolidDigitCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64*7*7, 128), nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))\n",
    "\n",
    "model = SolidDigitCNN().to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=LR)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "print('Parameters:', sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c739bb",
   "metadata": {},
   "source": [
    "## 4) Training loop — forward → loss → backward → step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea35b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    total, correct, n = 0.0, 0, 0\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            loss = crit(logits, y)\n",
    "            if train:\n",
    "                opt.zero_grad(); loss.backward(); opt.step()\n",
    "            total += loss.item()*x.size(0)\n",
    "            correct += (logits.argmax(1) == y).sum().item()\n",
    "            n += x.size(0)\n",
    "    return total/n, correct/n\n",
    "\n",
    "history = {'train_acc':[], 'val_acc':[]}\n",
    "t0 = time.time()\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, True)\n",
    "    va_loss, va_acc = run_epoch(val_loader,   False)\n",
    "    history['train_acc'].append(tr_acc); history['val_acc'].append(va_acc)\n",
    "    print(f\"Epoch {epoch:02d} | train acc={tr_acc*100:.2f}% | val acc={va_acc*100:.2f}%\")\n",
    "print(f\"Training time: {time.time()-t0:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd849a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5.2,3.2))\n",
    "plt.plot(history['val_acc'])\n",
    "plt.xlabel('epoch'); plt.ylabel('val acc'); plt.title('Validation accuracy'); plt.ylim(0,1); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8096f6e3",
   "metadata": {},
   "source": [
    "## 6) Robust preprocessing for hand-drawn digits (MNIST-like)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d85c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage as ndi\n",
    "\n",
    "def preprocess_to_mnist(x_gray01):\n",
    "    inv = 1.0 - x_gray01\n",
    "    h,w = inv.shape\n",
    "    scale = 20.0 / max(h,w)\n",
    "    pil = Image.fromarray((inv*255).astype(np.uint8)).resize(\n",
    "        (max(1, int(w*scale)), max(1, int(h*scale))), Image.BILINEAR\n",
    "    )\n",
    "    small = np.array(pil).astype(np.float32)/255.0\n",
    "    pad = np.pad(small, ((14,14),(14,14)), mode='constant')\n",
    "    cy, cx = ndi.center_of_mass(pad) if pad.sum()>0 else (pad.shape[0]/2, pad.shape[1]/2)\n",
    "    cy, cx = int(cy), int(cx)\n",
    "    y0, x0 = cy-14, cx-14\n",
    "    canvas = pad[y0:y0+28, x0:x0+28]\n",
    "    if canvas.shape != (28,28):\n",
    "        canvas = pad[:28,:28]\n",
    "    tens = torch.from_numpy(canvas[None,None,:,:]).float()\n",
    "    tens = (tens - MNIST_MEAN) / MNIST_STD\n",
    "    return tens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e93c5",
   "metadata": {},
   "source": [
    "## 7) Draw **one digit** (JupyterLab-friendly) and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0611c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = ny = CANVAS_INTERNAL\n",
    "canvas = Canvas(\n",
    "    width=nx, height=ny, sync_image_data=True,\n",
    "    layout=Layout(width=f'{DISPLAY_PX}px', height=f'{DISPLAY_PX}px', border='1px solid #ccc')\n",
    ")\n",
    "canvas.fill_style = 'white'; canvas.fill_rect(0,0,nx,ny)\n",
    "canvas.stroke_style = 'black'\n",
    "\n",
    "brush = IntSlider(value=BRUSH_INIT, min=6, max=24, step=1, description='Brush')\n",
    "canvas.line_width = brush.value\n",
    "def _set_brush(ch): canvas.line_width = ch['new']\n",
    "brush.observe(_set_brush, names='value')\n",
    "\n",
    "is_drawing, last = False, None\n",
    "def on_down(x, y):\n",
    "    global is_drawing, last\n",
    "    is_drawing, last = True, (x,y)\n",
    "def on_move(x, y):\n",
    "    global is_drawing, last\n",
    "    if not is_drawing: return\n",
    "    lx, ly = last if last else (x,y)\n",
    "    canvas.begin_path(); canvas.move_to(lx, ly); canvas.line_to(x, y); canvas.stroke()\n",
    "    last = (x,y)\n",
    "def on_up(x, y):\n",
    "    global is_drawing, last\n",
    "    is_drawing, last = False, None\n",
    "canvas.on_mouse_down(on_down); canvas.on_mouse_move(on_move); canvas.on_mouse_up(on_up)\n",
    "\n",
    "btn_clear = Button(description='Clear', button_style='warning')\n",
    "btn_pred  = Button(description='Predict', button_style='success')\n",
    "out_lbl   = HTML(value='Draw one digit, then click <b>Predict</b>.')\n",
    "\n",
    "def clear_canvas(_):\n",
    "    canvas.fill_style = 'white'; canvas.fill_rect(0,0,nx,ny)\n",
    "btn_clear.on_click(clear_canvas)\n",
    "\n",
    "def predict_canvas(_):\n",
    "    data = np.asarray(canvas.get_image_data())\n",
    "    rgb  = data[..., :3].astype(np.float32)\n",
    "    gray = (0.299*rgb[...,0] + 0.587*rgb[...,1] + 0.114*rgb[...,2]) / 255.0\n",
    "    x = preprocess_to_mnist(gray)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x.to(device))\n",
    "        pred = logits.argmax(1).item()\n",
    "        conf = torch.softmax(logits, dim=1).max(1).values.item()\n",
    "    out_lbl.value = f\"<b>Prediction:</b> {pred}  (confidence {conf:.2f})\"\n",
    "\n",
    "btn_pred.on_click(predict_canvas)\n",
    "\n",
    "VBox([canvas, HBox([btn_clear, btn_pred, brush]), out_lbl])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d59b57b",
   "metadata": {},
   "source": [
    "## 8) Wrap-up (talk track)\n",
    "\n",
    "- **Augmentations** toughen the model (rot/shift/shear).  \n",
    "- **BatchNorm + Dropout** stabilize and regularize.  \n",
    "- **MNIST-like centering** of your drawing (resize→pad→center of mass) reduces confusions like **7 vs 9**.  \n",
    "- Same **normalization** for training and inference keeps behavior consistent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
