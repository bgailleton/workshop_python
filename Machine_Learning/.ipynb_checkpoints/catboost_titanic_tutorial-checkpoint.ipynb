{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6612ab1e",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸš¢ CatBoost in 10 Minutes: Titanic Survival â€” Training, Explainability, & Whatâ€‘Ifs\n",
    "\n",
    "This miniâ€‘tutorial introduces **gradient boosting** (trees) and **CatBoost** with a real, mixedâ€‘type dataset (*Titanic*).\n",
    "Youâ€™ll train a model, evaluate it, interpret predictions with **SHAP**, and try an **interactive whatâ€‘if simulator**.\n",
    "\n",
    "**Why CatBoost?** It handles **categoricals** & **missing values** natively, needs minimal preprocessing, and gives calibrated probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177f4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# â–¶ï¸ Install (run once)\n",
    "!pip -q install catboost seaborn scikit-learn ipywidgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a20f8c7",
   "metadata": {},
   "source": [
    "\n",
    "## 0) What is Gradient Boosting (GBDT)? *30â€‘second mental model*\n",
    "\n",
    "- We fit **many small decision trees** sequentially.  \n",
    "- Each new tree focuses on **errors** of the current model, improving stepâ€‘byâ€‘step.  \n",
    "- CatBoost = a highâ€‘quality GBDT library with smart handling of **categorical features** and **overfitting**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155e7c52",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Imports & dataset (mixed numeric/categorical + NaNs)\n",
    "\n",
    "We use Seabornâ€™s **Titanic** dataset. The target is `survived` (renamed `y`).  \n",
    "We keep a small but diverse set of features (class, sex, age, fare, family, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd13dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd, numpy as np, seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, RocCurveDisplay\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import ipywidgets as W\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load Titanic\n",
    "df = sns.load_dataset(\"titanic\")\n",
    "cols = ['survived','pclass','sex','age','sibsp','parch','fare','embarked','class','who','adult_male','alone']\n",
    "df = df[cols].rename(columns={'survived':'y'})\n",
    "\n",
    "# Split\n",
    "X, y = df.drop(columns='y'), df['y']\n",
    "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "# Categorical columns by dtype\n",
    "cat_cols = X.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
    "\n",
    "def make_cats_safe(df, cat_cols):\n",
    "    \\\"\\\"\\\"Ensure categoricals are plain strings with 'NA' instead of missing.\\\"\\\"\\\"\n",
    "    df = df.copy()\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].astype('object')\n",
    "        df[c] = df[c].where(df[c].notna(), 'NA').astype(str)\n",
    "    return df\n",
    "\n",
    "Xtr = make_cats_safe(Xtr, cat_cols)\n",
    "Xte = make_cats_safe(Xte, cat_cols)\n",
    "\n",
    "print(\\\"Categoricals:\\\", cat_cols)\n",
    "print(\\\"Residual NaNs in categoricals (train,test):\\\",\n",
    "      Xtr[cat_cols].isna().sum().sum(), Xte[cat_cols].isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87707cba",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Model: CatBoostClassifier (GBDT for classification)\n",
    "\n",
    "Key knobs (kept modest for speed):\n",
    "- `iterations` (# trees), `learning_rate` (step size), `depth` (tree depth)  \n",
    "- `eval_metric='AUC'` because class imbalance & calibrated ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3588caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = dict(\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='AUC',\n",
    "    iterations=600,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model = CatBoostClassifier(**params)\n",
    "\n",
    "train_pool = Pool(Xtr, ytr, cat_features=cat_cols)\n",
    "valid_pool = Pool(Xte, yte, cat_features=cat_cols)\n",
    "\n",
    "model.fit(train_pool, eval_set=valid_pool)\n",
    "\n",
    "proba = model.predict_proba(valid_pool)[:,1]\n",
    "pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "print(f\\\"AUC:      {roc_auc_score(yte, proba):.3f}\\\")\n",
    "print(f\\\"Accuracy: {accuracy_score(yte, pred):.3f}\\\")\n",
    "print(classification_report(yte, pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b5b42d",
   "metadata": {},
   "source": [
    "\n",
    "## 3) ROC curve â€” quick visual of ranking quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8777c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RocCurveDisplay.from_predictions(yte, proba)\n",
    "plt.title(\\\"CatBoost ROC â€” Titanic\\\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b617d48",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Why did the model predict that? (SHAP)\n",
    "\n",
    "CatBoost can return **ShapValues**: featureâ€‘wise contributions that explain an individual prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e33542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SHAP values for validation set (last column is expected value / base)\n",
    "sv = model.get_feature_importance(valid_pool, type='ShapValues')\n",
    "\n",
    "row_idx = 0  # try different rows\n",
    "shap_vals = sv[row_idx, :-1]\n",
    "base = sv[row_idx, -1]\n",
    "\n",
    "row = Xte.iloc[row_idx]\n",
    "p_row = model.predict_proba(row.to_frame().T)[0,1]\n",
    "\n",
    "contrib = pd.DataFrame({\n",
    "    'feature': Xtr.columns,\n",
    "    'value': [row[c] for c in Xtr.columns],\n",
    "    'shap': shap_vals\n",
    "}).sort_values('shap', ascending=False)\n",
    "\n",
    "display(HTML(f\\\"<h4>Passenger preview â€” predicted survival p = {p_row:.3f}</h4>\\\"))\n",
    "display(row.to_frame().T)\n",
    "display(contrib.head(10).style.format({'shap':'{:.3f}'}).set_caption(\\\"Top positive contributions â†‘\\\"))\n",
    "display(contrib.tail(10).style.format({'shap':'{:.3f}'}).set_caption(\\\"Top negative contributions â†“\\\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a4adfc",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Whatâ€‘If Survival Simulator (interactive)\n",
    "\n",
    "Adjust inputs and see the **probability** update instantly.  \n",
    "This mirrors the training schema & preprocessing (categoricals â‡’ strings with `'NA'`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ed175b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pclass_to_class = {1:'First', 2:'Second', 3:'Third'}\n",
    "\n",
    "def predict_live(pclass, sex, age, sibsp, parch, fare, embarked, alone):\n",
    "    row = {\n",
    "        'pclass': pclass,\n",
    "        'sex': sex,\n",
    "        'age': None if age < 0 else age,  # allow -1 to mean NA\n",
    "        'sibsp': sibsp,\n",
    "        'parch': parch,\n",
    "        'fare': float(fare),\n",
    "        'embarked': embarked,\n",
    "        'class': pclass_to_class[pclass],\n",
    "        'who': 'woman' if sex=='female' else ('man' if (age >= 16 or age < 0) else 'child'),\n",
    "        'adult_male': bool(sex=='male' and (age >= 16 or age < 0)),\n",
    "        'alone': bool(alone)\n",
    "    }\n",
    "    row_df = make_cats_safe(pd.DataFrame([row]), cat_cols)\n",
    "    p = model.predict_proba(row_df)[0,1]\n",
    "    html = f\\\"\\\"\\\"\\n    <div style='padding:8px;border-left:6px solid #0a7; background:#eefaf5; width:max-content'>\\n      <b>Predicted survival probability:</b> {p:.3f}\\n    </div>\\\"\\\"\\\"\n",
    "    display(HTML(html))\n",
    "\n",
    "W.interact(\n",
    "    predict_live,\n",
    "    pclass=W.IntSlider(value=2, min=1, max=3, step=1, description='pclass'),\n",
    "    sex=W.Dropdown(options=['male','female'], value='female', description='sex'),\n",
    "    age=W.FloatSlider(value=28, min=-1, max=80, step=1, description='age (-1=NA)'),\n",
    "    sibsp=W.IntSlider(value=0, min=0, max=6, step=1, description='siblings'),\n",
    "    parch=W.IntSlider(value=0, min=0, max=6, step=1, description='parents'),\n",
    "    fare=W.FloatLogSlider(value=32, base=10, min=0, max=3, step=0.01, description='fare'),\n",
    "    embarked=W.Dropdown(options=sorted(X['embarked'].dropna().unique()), value='S', description='embarked'),\n",
    "    alone=W.Checkbox(value=True, description='alone')\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9748c4",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Takeaways\n",
    "\n",
    "- **GBDT** = many small trees learned sequentially; each tree corrects prior errors.  \n",
    "- **CatBoost** shines on **categoricals** & **messy realâ€‘world data** with minimal prep.  \n",
    "- You trained, evaluated (AUC/ROC), **explained** with SHAP, and ran **whatâ€‘if** scenarios.\n",
    "\n",
    "**Next steps:** try monotonic constraints (e.g., higher `fare` â‡’ nonâ€‘decreasing survival), add text features, or tune `iterations/learning_rate/depth`.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
